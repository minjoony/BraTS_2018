{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 gpu만 사용하도록 설정\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file format : nii.gz file\n",
    "# Dataset : BraTS 2018 Dataset\n",
    "# Framework : Pytorch\n",
    "# Network : UNet\n",
    "# Goal : Tumor segmentation from brain mri img\n",
    "\n",
    "### 1. Build U-Net model & Loss function(dice coefficient)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv(in_dim, out_dim, kernel_size):\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_dim, kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm2d(num_features = out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            return model\n",
    "\n",
    "        def deconv(in_dim, out_dim, kernel_size):\n",
    "            stride = 2\n",
    "            padding = 1\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_dim, out_dim, kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            return model\n",
    "        \n",
    "        # Contracting path (Encoder)\n",
    "        num_filter = 8\n",
    "        \n",
    "        self.conv1_1 = conv(in_dim=4, out_dim=num_filter, kernel_size=3)\n",
    "        self.conv1_2 = conv(num_filter, num_filter, 3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2_1 = conv(num_filter, num_filter*2, 3)\n",
    "        self.conv2_2 = conv(num_filter*2, num_filter*2, 3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3_1 = conv(num_filter*2, num_filter*4, 3)\n",
    "        self.conv3_2 = conv(num_filter*4, num_filter*4, 3)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv4_1 = conv(num_filter*4, num_filter*8, 3)\n",
    "        self.conv4_2 = conv(num_filter*8, num_filter*8, 3)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv5_1 = conv(num_filter*8, num_filter*16, 3)\n",
    "        self.conv5_2 = conv(num_filter*16, num_filter*16, 3)\n",
    "        \n",
    "        # Expansive path (Decoder)\n",
    "        self.deconv6 = deconv(in_dim = num_filter*16, out_dim = num_filter*8, kernel_size = 4)\n",
    "        self.conv6_1 = conv(num_filter*16, num_filter*8, 3)\n",
    "        self.conv6_2 = conv(num_filter*8, num_filter*8, 3)\n",
    "        \n",
    "        self.deconv7 = deconv(num_filter*8, num_filter*4, 4)\n",
    "        self.conv7_1 = conv(num_filter*8, num_filter*4, 3)\n",
    "        self.conv7_2 = conv(num_filter*4, num_filter*4, 3)\n",
    "        \n",
    "        self.deconv8 = deconv(num_filter*4, num_filter*2, 4)\n",
    "        self.conv8_1 = conv(num_filter*4, num_filter*2, 3)\n",
    "        self.conv8_2 = conv(num_filter*2, num_filter*2, 3)\n",
    "        \n",
    "        self.deconv9 = deconv(num_filter*2, num_filter, 4)\n",
    "        self.conv9_1 = conv(num_filter*2, num_filter, 3)\n",
    "        self.conv9_2 = conv(num_filter, num_filter, 3)\n",
    "        \n",
    "        self.out = nn.Conv2d(in_channels=num_filter, out_channels=2, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "#                 nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "#                 nn.init.kaiming_normal_(m.weight.data)\n",
    "    \n",
    "    def forward(self, input, prt=False):\n",
    "        conv1_1 = self.conv1_1(input)\n",
    "        conv1_2 = self.conv1_2(conv1_1)\n",
    "        pool1 = self.pool1(conv1_2)\n",
    "        \n",
    "        conv2_1 = self.conv2_1(pool1)\n",
    "        conv2_2 = self.conv2_2(conv2_1)\n",
    "        pool2 = self.pool2(conv2_2)\n",
    "        \n",
    "        conv3_1 = self.conv3_1(pool2)\n",
    "        conv3_2 = self.conv3_2(conv3_1)\n",
    "        pool3 = self.pool3(conv3_2)\n",
    "\n",
    "        conv4_1 = self.conv4_1(pool3)\n",
    "        conv4_2 = self.conv4_2(conv4_1)\n",
    "        pool4 = self.pool4(conv4_2)\n",
    "\n",
    "        conv5_1 = self.conv5_1(pool4)\n",
    "        conv5_2 = self.conv5_2(conv5_1)\n",
    "\n",
    "        deconv6 = self.deconv6(conv5_2)\n",
    "        concat6 = torch.cat((deconv6, conv4_2), dim=1)\n",
    "        conv6_1 = self.conv6_1(concat6)\n",
    "        conv6_2 = self.conv6_2(conv6_1)\n",
    "        \n",
    "        deconv7 = self.deconv7(conv6_2)\n",
    "        concat7 = torch.cat((deconv7, conv3_2), dim=1)\n",
    "        conv7_1 = self.conv7_1(concat7)\n",
    "        conv7_2 = self.conv7_2(conv7_1)\n",
    "        \n",
    "        deconv8 = self.deconv8(conv7_2)\n",
    "        concat8 = torch.cat((deconv8, conv2_2), dim=1)\n",
    "        conv8_1 = self.conv8_1(concat8)\n",
    "        conv8_2 = self.conv8_2(conv8_1)\n",
    "        \n",
    "        deconv9 = self.deconv9(conv8_2)\n",
    "        concat9 = torch.cat((deconv9, conv1_2), dim=1)\n",
    "        conv9_1 = self.conv9_1(concat9)\n",
    "        conv9_2 = self.conv9_2(conv9_1)\n",
    "        \n",
    "        output = self.out(conv9_2)\n",
    "        output = softmax(output, dim=1)\n",
    "        \n",
    "        if(prt == True):\n",
    "            print(\"input shape :\", input.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"conv1_1 shape :\", conv1_1.shape)\n",
    "            print(\"conv1_2 shape :\", conv1_2.shape)\n",
    "            print(\"pool1 shape :\", pool1.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"conv2_1 shape :\", conv2_1.shape)\n",
    "            print(\"conv2_2 shape :\", conv2_2.shape)\n",
    "            print(\"pool2 shape :\", pool2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"conv3_1 shape :\", conv3_1.shape)\n",
    "            print(\"conv3_2 shape :\", conv3_2.shape)\n",
    "            print(\"pool3 shape :\", pool3.shape)\n",
    "            print(\"\")\n",
    "\n",
    "            print(\"conv4_1 shape :\", conv4_1.shape)\n",
    "            print(\"conv4_2 shape :\", conv4_2.shape)\n",
    "            print(\"pool4 shape :\", pool4.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"conv5_1 shape :\", conv5_1.shape)\n",
    "            print(\"conv5_2 shape :\", conv5_2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"deconv6_shape :\", deconv6.shape)\n",
    "            print(\"concat6_shape :\", concat6.shape)\n",
    "            print(\"conv6_1 shape :\", conv6_1.shape)\n",
    "            print(\"conv6_2 shape :\", conv6_2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"deconv7_shape :\", deconv7.shape)\n",
    "            print(\"concat7_shape :\", concat7.shape)\n",
    "            print(\"conv7_1 shape :\", conv7_1.shape)\n",
    "            print(\"conv7_2 shape :\", conv7_2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"deconv8_shape :\", deconv8.shape)\n",
    "            print(\"concat8_shape :\", concat8.shape)\n",
    "            print(\"conv8_1 shape :\", conv8_1.shape)\n",
    "            print(\"conv8_2 shape :\", conv8_2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"deconv9_shape :\", deconv9.shape)\n",
    "            print(\"concat9_shape :\", concat9.shape)\n",
    "            print(\"conv9_1 shape :\", conv9_1.shape)\n",
    "            print(\"conv9_2 shape :\", conv9_2.shape)\n",
    "            print(\"\")\n",
    "            \n",
    "            print(\"\\noutput shape :\", output.shape)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# loss function : dice coefficient\n",
    "def dice_coef(predict, target):\n",
    "    smooth = 1\n",
    "\n",
    "    intersection = (predict * target).sum()\n",
    "    loss = 1 - ((2.0 * intersection + smooth) / (predict.sum() + target.sum() + smooth))\n",
    "    \n",
    "#     print('intersection :', intersection)\n",
    "#     print('boonja :', (2.0 * intersection + smooth))\n",
    "#     print('boonmo :', (predict.sum() + target.sum() + smooth))\n",
    "#     print('loss :', loss)   \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Load the dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.datasets import MNI152_FILE_PATH\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "torch.set_printoptions(threshold=99999, linewidth=99999)\n",
    "\n",
    "def convNii2np(paths, flag):\n",
    "    crop_from = 24\n",
    "    crop_to = 216\n",
    "    depth_from = 14\n",
    "    depth_to = 142\n",
    "    result_list = []\n",
    "    \n",
    "    for path in paths:\n",
    "        np_img_list = []\n",
    "        \n",
    "        for img in path:\n",
    "            img_data = nib.load(img)\n",
    "            np_img_data = np.array(img_data.get_fdata())\n",
    "            np_img_data = np_img_data[crop_from:crop_to, crop_from:crop_to, depth_from:depth_to]\n",
    "            np_img_data = np_img_data.transpose(2,0,1).reshape(128, 192, 192)\n",
    "            \n",
    "            # convert input img to gray scale.\n",
    "            if(flag == 'input'):\n",
    "                np_img_data = (np_img_data / np.max(np_img_data)) * 255\n",
    "                np_img_data = np_img_data.astype(np.uint8)\n",
    "                \n",
    "                # standardization\n",
    "                np_img_data = (np_img_data - np.mean(np_img_data)) / np.std(np_img_data)\n",
    "                \n",
    "                # normalization\n",
    "#                 np_img_data = (np_img_data - np.min(np_img_data[np_img_data>0])) / (np.max(np_img_data) - np.min(np_img_data[np_img_data>0]))\n",
    "                \n",
    "            # convert label img to binary scale.\n",
    "            elif(flag == 'label'):\n",
    "                np_img_list.append(np_img_data)\n",
    "                np_img_data[np_img_data > 1] = 1\n",
    "                np_img_data = 1 - np_img_data\n",
    "            \n",
    "            np_img_list.append(np_img_data)\n",
    "            \n",
    "        np_input_data = np.concatenate(np_img_list, axis=0)\n",
    "        result_list.append(np_input_data)\n",
    "            \n",
    "    return result_list\n",
    "\n",
    "# Set up the directories.\n",
    "base_dir = './data/'\n",
    "train_dir = base_dir + 'train/'\n",
    "valid_dir = base_dir + 'valid/'\n",
    "\n",
    "all_dir = train_dir + 'ALL/'\n",
    "hgg_dir = train_dir + 'HGG/'\n",
    "lgg_dir = train_dir + 'LGG/'\n",
    "train_sub_dir = []\n",
    "valid_sub_dir = []\n",
    "\n",
    "# Get train & valid's sub directories\n",
    "train_dirnames = os.listdir(all_dir)\n",
    "valid_dirnames = os.listdir(valid_dir)\n",
    "\n",
    "for dirname in train_dirnames:\n",
    "    train_sub_dir.append(dirname)\n",
    "\n",
    "for dirname in valid_dirnames:\n",
    "    valid_sub_dir.append(dirname)\n",
    "\n",
    "# Get dataset paths\n",
    "channels = ['flair', 't1', 't1ce', 't2']\n",
    "\n",
    "train_paths = []\n",
    "t_label_paths = []\n",
    "np_train_list = []\n",
    "np_t_label_list = []\n",
    "\n",
    "valid_paths = []\n",
    "v_label_paths = []\n",
    "np_valid_list = []\n",
    "np_v_label_list = []\n",
    "\n",
    "for sub_dir_name in train_sub_dir:\n",
    "    train_paths.append([os.path.join(all_dir + sub_dir_name + '/' + sub_dir_name + '_' + channel + '.nii.gz') for channel in channels])\n",
    "    t_label_paths.append([os.path.join(all_dir + sub_dir_name + '/' + sub_dir_name + '_seg.nii.gz')])\n",
    "    \n",
    "for sub_dir_name in valid_sub_dir:\n",
    "    valid_paths.append([os.path.join(valid_dir + sub_dir_name + '/' + sub_dir_name + '_' + channel + '.nii.gz') for channel in channels])\n",
    "    v_label_paths.append([os.path.join(valid_dir + sub_dir_name + '/' + sub_dir_name + '_seg.nii.gz')])    \n",
    "        \n",
    "# Convert nii to tensor with reshaping (4, 128, 192, 192)\n",
    "print('------ Making dataset tensor ------')\n",
    "np_train_list = convNii2np(train_paths, 'input')\n",
    "np_valid_list = convNii2np(valid_paths, 'input')\n",
    "np_t_label_list = convNii2np(t_label_paths, 'label')   \n",
    "np_v_label_list = convNii2np(v_label_paths, 'label')\n",
    "\n",
    "train_tensor_list = []\n",
    "valid_tensor_list = []\n",
    "t_label_tensor_list = []\n",
    "v_label_tensor_list = []\n",
    "\n",
    "for input_, label_ in zip(np_train_list, np_t_label_list):\n",
    "    temp_tensor = torch.from_numpy(input_)\n",
    "    temp_tensor = temp_tensor.reshape(4, 128, 192, 192)\n",
    "    temp_tensor = temp_tensor.transpose(0, 1)\n",
    "    train_tensor_list.append(temp_tensor)\n",
    "    \n",
    "    temp_tensor = torch.from_numpy(label_)\n",
    "    temp_tensor = temp_tensor.reshape(2, 128, 192, 192)\n",
    "    temp_tensor = temp_tensor.transpose(0, 1)\n",
    "    t_label_tensor_list.append(temp_tensor)\n",
    "\n",
    "for input_, label_ in zip(np_valid_list, np_v_label_list):\n",
    "    temp_tensor = torch.from_numpy(input_)\n",
    "    temp_tensor = temp_tensor.reshape(4, 128, 192, 192)\n",
    "    temp_tensor = temp_tensor.transpose(0, 1)\n",
    "    valid_tensor_list.append(temp_tensor)\n",
    "    \n",
    "    temp_tensor = torch.from_numpy(label_)\n",
    "    temp_tensor = temp_tensor.reshape(2, 128, 192, 192)\n",
    "    temp_tensor = temp_tensor.transpose(0, 1)\n",
    "    v_label_tensor_list.append(temp_tensor)\n",
    "\n",
    "print(\"Num of train data and label data : %d, %d\" %(len(train_tensor_list), len(t_label_tensor_list)))\n",
    "print(\"Num of valid data and label data : %d, %d\" %(len(valid_tensor_list), len(v_label_tensor_list)))\n",
    "print(\"shape of the train & label : \", train_tensor_list[0].shape, t_label_tensor_list[0].shape)\n",
    "print(\"shape of the valid & label : \", valid_tensor_list[0].shape, v_label_tensor_list[0].shape)\n",
    "print('------ Done ------')\n",
    "\n",
    "# Save the memory\n",
    "del train_sub_dir\n",
    "del valid_sub_dir\n",
    "\n",
    "del train_paths\n",
    "del valid_paths\n",
    "del t_label_paths\n",
    "del v_label_paths\n",
    "\n",
    "del np_train_list\n",
    "del np_t_label_list\n",
    "del np_valid_list\n",
    "del np_v_label_list\n",
    "\n",
    "train_tensors = torch.Tensor(len(train_tensor_list), 128, 4, 192, 192)\n",
    "torch.cat(train_tensor_list, dim=0, out=train_tensors)\n",
    "del train_tensor_list\n",
    "\n",
    "valid_tensors = torch.Tensor(len(valid_tensor_list), 128, 4, 192, 192)\n",
    "torch.cat(valid_tensor_list, dim=0, out=valid_tensors)\n",
    "del valid_tensor_list\n",
    "\n",
    "t_label_tensors = torch.Tensor(len(t_label_tensor_list), 128, 2, 192, 192)\n",
    "torch.cat(t_label_tensor_list, dim=0, out=t_label_tensors)\n",
    "del t_label_tensor_list\n",
    "\n",
    "v_label_tensors = torch.Tensor(len(v_label_tensor_list), 128, 2, 192, 192)\n",
    "torch.cat(v_label_tensor_list, dim=0, out=v_label_tensors)\n",
    "del v_label_tensor_list\n",
    "\n",
    "# Set the Dataset\n",
    "train_dataset = TensorDataset(train_tensors, t_label_tensors)\n",
    "valid_dataset = TensorDataset(valid_tensors, v_label_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('\\ndevice :', device)\n",
    "\n",
    "# hyper parameters\n",
    "lr = 1e-4\n",
    "num_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Load the data using DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "net = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "t_loss_arr = []\n",
    "v_loss_arr = []\n",
    "\n",
    "print('\\n------ Hyper Params ------')\n",
    "print(\"learning rate: %.4e\" % lr)\n",
    "print(\"number of epoch: %d\" % num_epoch)\n",
    "print(\"batch size: %d\" % batch_size)\n",
    "\n",
    "print('\\n\\n------ Start Training ------')\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    \n",
    "    # train the model\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    ####################################################################\n",
    "#     fig = plt.figure()\n",
    "#     rows = 1\n",
    "#     cols = 3\n",
    "#     custom_depth = 0\n",
    "    ####################################################################    \n",
    "    \n",
    "    for t_input, t_label in train_loader:\n",
    "\n",
    "        ####################################################################\n",
    "#         np_t_input_img = t_input.detach().numpy()\n",
    "#         np_t_input_img = np.array(np_t_input_img)\n",
    "#         print(np.max(np_t_input_img))\n",
    "#         t_input_img = np_t_input_img[custom_depth, 0, :, :]\n",
    "#         ax = fig.add_subplot(rows, cols, 1)\n",
    "#         ax.imshow(t_input_img, vmin=0, vmax=255, cmap='gray')\n",
    "#         ax.set_title('input')\n",
    "        ####################################################################\n",
    "\n",
    "        # Forward propagation\n",
    "        t_input = t_input.cuda()\n",
    "        t_label = t_label.cuda()\n",
    "        \n",
    "        t_output = net(t_input.float())\n",
    "        \n",
    "        ####################################################################\n",
    "#         t_output_img = t_output.cpu()\n",
    "#         np_t_output_img = t_output_img.detach().numpy()\n",
    "#         np_t_output_img = np.array(np_t_output_img)\n",
    "#         np_t_output_img = np_t_output_img.argmax(1)\n",
    "        \n",
    "#         t_result = np_t_output_img[0, :, :]\n",
    "#         ax = fig.add_subplot(rows, cols, 2)\n",
    "#         ax.imshow(t_result)#, cmap='gray')\n",
    "#         ax.set_title('predict')\n",
    "\n",
    "#         t_label_img = t_label.cpu()\n",
    "#         t_label_img = t_label_img[custom_depth, 0, :, :]\n",
    "#         ax = fig.add_subplot(rows, cols, 3)\n",
    "#         ax.imshow(t_label_img)#, cmap='gray')\n",
    "#         ax.set_title('Label')\n",
    "        \n",
    "#         plt.savefig('forward_result.png')\n",
    "        ####################################################################\n",
    "        \n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()    # 역전파 실행 전 grad 값 0으로 만듦\n",
    "        loss = 0        \n",
    "\n",
    "        for i in range(0, 2):\n",
    "            loss_ = dice_coef(t_output[:, i, :, :], t_label[:, 1-i, :, :])\n",
    "#             print(loss_)\n",
    "            loss += loss_\n",
    "        loss = (loss / 2)\n",
    "        loss.backward()          # 매개변수에 대한 loss의 grad 값 계산\n",
    "        optimizer.step()         # 매개변수 갱신\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         ''''''\n",
    "#         t_output = t_output.argmax(1)\n",
    "        \n",
    "#         loss_ = dice_coef(t_output[:, :, :], t_label[:, 0, :, :])\n",
    "#         loss += loss_\n",
    "#         loss_.requires_grad = True\n",
    "#         loss_.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss_\n",
    "#         ''''''\n",
    "        \n",
    "        \n",
    "    print(\"Train: EPOCH %04d / %04d | LOSS %.4f\" %(epoch, num_epoch, epoch_loss/len(train_dataset)))\n",
    "    t_loss_arr.append(epoch_loss/len(train_dataset))\n",
    "    \n",
    "    # validate the model\n",
    "    net.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for v_input, v_label in valid_loader:\n",
    "        v_input = v_input.cuda()\n",
    "        v_label = v_label.cuda()\n",
    "        \n",
    "        v_output = net(v_input.float())\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(0, 2):\n",
    "            loss_ = dice_coef(v_output[:, i, :, :], v_label[:, 1-i, :, :])\n",
    "            loss += loss_\n",
    "        loss = (loss / 2)\n",
    "        epoch_loss += loss.item()\n",
    "    print(\"Valid: EPOCH %04d / %04d | LOSS %.4f\\n\" %(epoch, num_epoch, epoch_loss/len(valid_dataset)))\n",
    "    v_loss_arr.append(epoch_loss/len(valid_dataset))\n",
    "    \n",
    "print(\"------ Finished Training ------\")\n",
    "epoch_list = range(1, num_epoch+1)\n",
    "plt.plot(epoch_list, np.array(t_loss_arr), 'y')\n",
    "plt.plot(epoch_list, np.array(v_loss_arr), 'c')\n",
    "plt.title('Loss Graph')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend((['train loss', 'validation loss']))\n",
    "plt.savefig('loss graph2D.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Test the model\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)    # numpy 생략(...) 없애기\n",
    "\n",
    "test_dir = base_dir + 'test/'\n",
    "\n",
    "test_sub_dir = []\n",
    "test_img_list = []\n",
    "label_img_list = []\n",
    "np_test_data_list = []\n",
    "\n",
    "testdirnames = os.listdir(test_dir)\n",
    "for dirname in testdirnames:\n",
    "    test_sub_dir.append(dirname)\n",
    "    \n",
    "for test_sub_path in test_sub_dir:\n",
    "    test_img_list.append([os.path.join(test_dir + test_sub_path + '/' + test_sub_path + '_' + channel + '.nii.gz') for channel in channels])\n",
    "    label_img_list.append([os.path.join(test_dir + test_sub_path + '/' + test_sub_path + '_seg.nii.gz')])\n",
    "\n",
    "# predict the output image\n",
    "np_test_list = convNii2np(test_img_list, 'input')\n",
    "np_test_data = np.concatenate(np_test_list, axis = 0)\n",
    "test_tensor = torch.from_numpy(np_test_data)\n",
    "test_tensor = test_tensor.reshape(4, 128, 192, 192)\n",
    "test_tensor = test_tensor.transpose(0, 1)\n",
    "test_tensor = test_tensor.cuda()\n",
    "\n",
    "predict_img = net(test_tensor.float())\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 1\n",
    "cols = 2\n",
    "custom_depth = 50\n",
    "\n",
    "## predict image\n",
    "predict_img = predict_img.cpu()\n",
    "np_predict_img = predict_img.detach().numpy()\n",
    "np_predict_img = np.array(np_predict_img)\n",
    "np_predict_img = np_predict_img.argmax(1)\n",
    "\n",
    "test_result = np_predict_img[custom_depth, :, :]\n",
    "ax = fig.add_subplot(rows, cols, 1)\n",
    "ax.imshow(test_result)\n",
    "ax.set_title('Predict')\n",
    "\n",
    "# load the label image\n",
    "for label_img in label_img_list[0]:\n",
    "    label_nii = nib.load(label_img)\n",
    "    label_img = np.array(label_nii.get_fdata()[24:216, 24:216, 14:142])\n",
    "    label_img[label_img > 1] = 1\n",
    "    label_img = label_img.transpose(2,0,1).reshape(128, 192, 192)\n",
    "    label_img = label_img[custom_depth, :, :]\n",
    "    ax = fig.add_subplot(rows, cols, 2)\n",
    "    ax.imshow(label_img)\n",
    "    ax.set_title('Label')\n",
    "\n",
    "plt.savefig('result2D.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = './weights/'\n",
    "torch.save(net, PATH+'unet2D.pt')\n",
    "torch.save(net.state_dict(), PATH+'unet_state_dict2D.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BraTS",
   "language": "python",
   "name": "brats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
