{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 gpu만 사용하도록 설정\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file format : nii.gz file\n",
    "# Dataset : BraTS 2018 Dataset\n",
    "# Framework : Pytorch\n",
    "# Network : UNet\n",
    "# Goal : Tumor segmentation from brain mri img\n",
    "\n",
    "### 1. Load the dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.datasets import MNI152_FILE_PATH\n",
    "\n",
    "base_dir = './data/'\n",
    "train_dir = base_dir + 'train/'\n",
    "hgg_dir = train_dir + 'HGG/'\n",
    "lgg_dir = train_dir + 'LGG/'\n",
    "sub_dir = []\n",
    "\n",
    "# List up the train's sub directories\n",
    "dirnames = os.listdir(lgg_dir)\n",
    "for dirname in dirnames:\n",
    "    sub_dir.append(dirname)\n",
    "\n",
    "# sub_dir.append('Brats18_2013_0_1')    # Just for testing...\n",
    "\n",
    "# List up dataset\n",
    "channels = ['flair', 't1', 't1ce', 't2']\n",
    "\n",
    "train_paths = []\n",
    "label_paths = []\n",
    "np_train_list = []\n",
    "np_label_list = []\n",
    "\n",
    "for sub_dir_name in sub_dir:\n",
    "    train_paths.append([os.path.join(lgg_dir + sub_dir_name + '/' + sub_dir_name + '_' + channel + '.nii.gz') for channel in channels])\n",
    "    label_paths.append([os.path.join(lgg_dir + sub_dir_name + '/' + sub_dir_name + '_seg.nii.gz')])\n",
    "'''\n",
    "img_paths = [   [1.flair.nii.gz, 1.t1.nii.gz, 1.t1ce.nii.gz, 1.t2.nii.gz]\n",
    "                [2.flair.nii.gz, 2.t1.nii.gz, 2.t1ce.nii.gz, 2.t2.nii.gz]\n",
    "                ...\n",
    "            ]\n",
    "            \n",
    "label_paths = [ [1.seg.nii.gz]\n",
    "                [2.seg.nii.gz]\n",
    "                ...\n",
    "              ]            \n",
    "'''\n",
    "# Convert nii to numpy and reshape\n",
    "## Concatenate the train dataset to make tensor (4, 240, 240, 128)\n",
    "print('making train tensor...')\n",
    "depth_from = 14\n",
    "depth_to = 142\n",
    "\n",
    "for train_path in train_paths:\n",
    "    np_img_data_list = []\n",
    "    \n",
    "    for img in train_path:\n",
    "        img_data = nib.load(img)\n",
    "        np_img_data = np.array(img_data.get_fdata())\n",
    "        np_img_data = np_img_data[:, :, depth_from:depth_to]\n",
    "        np_img_data = np.reshape(np_img_data, (1, 240, 240, 128))\n",
    "        np_img_data_list.append(np_img_data)\n",
    "        \n",
    "    np_train_data = np.concatenate(np_img_data_list, axis=0)\n",
    "    np_train_list.append(np_train_data)\n",
    "\n",
    "## convert label dataset\n",
    "for label_path in label_paths:\n",
    "    for img in label_path:\n",
    "        img_data = nib.load(img)\n",
    "        np_img_data = np.array(img_data.get_fdata())\n",
    "        np_img_data = np_img_data[:, :, depth_from:depth_to]\n",
    "        np_img_data = np.reshape(np_img_data, (1, 240, 240, 128))\n",
    "        np_label_list.append(np_img_data)\n",
    "print('...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Build U-Net model & Loss function(dice coefficient)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv(in_dim, out_dim, kernel_size, channel_num):\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Conv3d(in_dim, out_dim, kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm3d(num_features = out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            return model\n",
    "\n",
    "        def deconv(in_dim, out_dim, kernel_size, channel_num):\n",
    "            stride = 2\n",
    "            padding = 0\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.ConvTranspose3d(in_dim, out_dim, kernel_size = kernel_size, stride = stride, padding = padding),\n",
    "                nn.BatchNorm3d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            return model\n",
    "        \n",
    "        # Contracting path (Encoder)\n",
    "        self.conv1_1 = conv(in_dim=4, out_dim=8, kernel_size=3, channel_num=4)\n",
    "        self.conv1_2 = conv(8, 8, 3, 4)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2_1 = conv(8, 16, 3, 4)\n",
    "        self.conv2_2 = conv(16, 16, 3, 4)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3_1 = conv(16, 32, 3, 4)\n",
    "        self.conv3_2 = conv(32, 32, 3, 4)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4_1 = conv(32, 64, 3, 4)\n",
    "        self.conv4_2 = conv(64, 64, 3, 4)\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv5_1 = conv(64, 128, 3, 4)\n",
    "        self.conv5_2 = conv(128, 128, 3, 4)\n",
    "        \n",
    "        # Expansive path (Decoder)\n",
    "        self.deconv6 = deconv(in_dim = 128, out_dim = 64, kernel_size = 2, channel_num = 4)\n",
    "        self.conv6_1 = conv(128, 64, 3, 4)\n",
    "        self.conv6_2 = conv(64, 64, 3, 4)\n",
    "        \n",
    "        self.deconv7 = deconv(64, 32, 2, 4)\n",
    "        self.conv7_1 = conv(64, 32, 3, 4)\n",
    "        self.conv7_2 = conv(32, 32, 3, 4)\n",
    "        \n",
    "        self.deconv8 = deconv(32, 16, 2, 4)\n",
    "        self.conv8_1 = conv(32, 16, 3, 4)\n",
    "        self.conv8_2 = conv(16, 16, 3, 4)\n",
    "        \n",
    "        self.deconv9 = deconv(16, 8, 2, 4)\n",
    "        self.conv9_1 = conv(16, 8, 3, 4)\n",
    "        self.conv9_2 = conv(8, 8, 3, 4)\n",
    "        \n",
    "        self.out = nn.Conv3d(in_channels=8, out_channels=4, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, input):\n",
    "#         print(\"input shape :\", input.shape)\n",
    "        conv1_1 = self.conv1_1(input)\n",
    "#         print(\"\\nconv1_1 shape :\", conv1_1.shape)\n",
    "        conv1_2 = self.conv1_2(conv1_1)\n",
    "#         print(\"conv1_2 shape :\", conv1_2.shape)\n",
    "        pool1 = self.pool1(conv1_2)\n",
    "#         print(\"pool1 shape :\", pool1.shape)\n",
    "        \n",
    "        conv2_1 = self.conv2_1(pool1)\n",
    "#         print(\"\\nconv2_1 shape :\", conv2_1.shape)\n",
    "        conv2_2 = self.conv2_2(conv2_1)\n",
    "#         print(\"conv2_2 shape :\", conv2_2.shape)\n",
    "        pool2 = self.pool2(conv2_2)\n",
    "#         print(\"pool2 shape :\", pool2.shape)\n",
    "        \n",
    "        conv3_1 = self.conv3_1(pool2)\n",
    "#         print(\"conv3_1 shape :\", conv3_1.shape)\n",
    "        conv3_2 = self.conv3_2(conv3_1)\n",
    "#         print(\"conv3_2 shape :\", conv3_2.shape)\n",
    "        pool3 = self.pool3(conv3_2)\n",
    "#         print(\"pool3 shape :\", pool3.shape)\n",
    "\n",
    "        \n",
    "        conv4_1 = self.conv4_1(pool3)\n",
    "#         print(\"\\nconv4_1 shape :\", conv4_1.shape)\n",
    "        conv4_2 = self.conv4_2(conv4_1)\n",
    "#         print(\"conv4_2 shape :\", conv4_2.shape)\n",
    "        pool4 = self.pool4(conv4_2)\n",
    "#         print(\"pool4 shape :\", pool4.shape)\n",
    "\n",
    "        conv5_1 = self.conv5_1(pool4)\n",
    "#         print(\"\\nconv5_1 shape :\", conv5_1.shape)\n",
    "        conv5_2 = self.conv5_2(conv5_1)\n",
    "#         print(\"conv5_2 shape :\", conv5_2.shape)\n",
    "\n",
    "        \n",
    "        deconv6 = self.deconv6(conv5_2)\n",
    "#         print(\"\\ndeconv6 shape :\", deconv6.shape)\n",
    "        concat6 = torch.cat((deconv6, conv4_2), dim=1)\n",
    "#         print(\"concat6 shape :\", concat6.shape)\n",
    "        conv6_1 = self.conv6_1(concat6)\n",
    "#         print(\"conv6_1 shape :\", conv6_1.shape)\n",
    "        conv6_2 = self.conv6_2(conv6_1)\n",
    "#         print(\"conv6_2 shape :\", conv6_2.shape)\n",
    "        \n",
    "        deconv7 = self.deconv7(conv6_2)\n",
    "        concat7 = torch.cat((deconv7, conv3_2), dim=1)\n",
    "        conv7_1 = self.conv7_1(concat7)\n",
    "        conv7_2 = self.conv7_2(conv7_1)\n",
    "        \n",
    "        deconv8 = self.deconv8(conv7_2)\n",
    "        concat8 = torch.cat((deconv8, conv2_2), dim=1)\n",
    "        conv8_1 = self.conv8_1(concat8)\n",
    "        conv8_2 = self.conv8_2(conv8_1)\n",
    "        \n",
    "        deconv9 = self.deconv9(conv8_2)\n",
    "        concat9 = torch.cat((deconv9, conv1_2), dim=1)\n",
    "        conv9_1 = self.conv9_1(concat9)\n",
    "        conv9_2 = self.conv9_2(conv9_1)\n",
    "#         print(\"\\nconv9_2 shape :\", conv9_2.shape)\n",
    "\n",
    "        \n",
    "        output = self.out(conv9_2)\n",
    "        output = softmax(output, dim=1)\n",
    "        \n",
    "#         if(prt == True):\n",
    "#             print(\"input shape :\", input.shape)\n",
    "#             print(\"\\n\")\n",
    "            \n",
    "#             print(\"conv1_1 shape :\", conv1_1.shape)\n",
    "#             print(\"conv1_2 shape :\", conv1_2.shape)\n",
    "#             print(\"pool1 shape :\", pool1.shape)\n",
    "#             print(\"\\n\")\n",
    "            \n",
    "#             print(\"conv2_1 shape :\", conv2_1.shape)\n",
    "#             print(\"conv2_2 shape :\", conv2_2.shape)\n",
    "#             print(\"pool2 shape :\", pool2.shape)\n",
    "#             print(\"\\n\")\n",
    "            \n",
    "#             print(\"conv3_1 shape :\", conv3_1.shape)\n",
    "#             print(\"conv3_2 shape :\", conv3_2.shape)\n",
    "#             print(\"pool3 shape :\", pool3.shape)\n",
    "#             print(\"\\n\")\n",
    "\n",
    "#             print(\"conv4_1 shape :\", conv4_1.shape)\n",
    "#             print(\"conv4_2 shape :\", conv4_2.shape)\n",
    "#             print(\"pool4 shape :\", pool4.shape)\n",
    "#             print(\"\\n\")\n",
    "\n",
    "#         print(\"\\noutput shape :\", output.shape)\n",
    "        return output\n",
    "\n",
    "# loss function : dice coefficient\n",
    "def dice_coef(predict, target):\n",
    "    smooth = 1.0\n",
    "    class_num = 4\n",
    "    \n",
    "    intersection = (predict * target).sum()\n",
    "    loss = 1 - ((2.0 * intersection + smooth) / (predict.sum() + target.sum() + smooth))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "### 3.1 Forward propagation\n",
    "train_tensor = torch.from_numpy(np_train_list[0])\n",
    "print(train_tensor.shape)\n",
    "train_tensor = train_tensor.reshape(1, 4, 240, 240, 128)\n",
    "# print(train_tensor.shape)\n",
    "\n",
    "tempUnet = UNet()\n",
    "output_tensor = tempUnet.forward(train_tensor.float())\n",
    "\n",
    "# predict_flair = output_tensor[0, 0, :, :]\n",
    "# t1_flair = output_tensor[0, 1, :, :]\n",
    "# t1ce_flair = output_tensor[0, 2, :, :]\n",
    "# t2_flair = output_tensor[0, 3, :, :]\n",
    "\n",
    "# forward-propagation 결과 img로 저장.\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "rows = 2\n",
    "cols = 4\n",
    "custom_depth = 65\n",
    "\n",
    "for i in range(1,5):\n",
    "    np_input_tensor = train_tensor.detach().numpy()\n",
    "    predict_img = np_input_tensor[0][i-1, :, :, custom_depth]\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i)\n",
    "    ax.imshow(predict_img)\n",
    "    ax.set_title('Origin_' + channels[i-1])\n",
    "    \n",
    "# for i in range(1,5):\n",
    "#     np_output_tensor = output_tensor.detach().numpy()\n",
    "#     forward_img = np_output_tensor[0][i-1, :, :, custom_depth]\n",
    "    \n",
    "#     ax = fig.add_subplot(rows, cols, i+4)\n",
    "#     ax.imshow(forward_img)\n",
    "#     ax.set_title('Predict_' + channels[i-1])\n",
    "    \n",
    "# plt.savefig('forward_img.png')\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)    # numpy 생략(...) 없애기\n",
    "print(output_tensor)\n",
    "\n",
    "np_output_tensor = output_tensor.detach().numpy()\n",
    "# print(np_output_tensor)\n",
    "\n",
    "forward_img = np_output_tensor[0][0, :, :, custom_depth]\n",
    "ax = fig.add_subplot(rows, cols, 5)\n",
    "ax.imshow(forward_img)\n",
    "ax.set_title('Predict')\n",
    "\n",
    "label_img = np_label_list[0][0, :, :, custom_depth]\n",
    "ax = fig.add_subplot(rows, cols, 6)\n",
    "ax.imshow(label_img)\n",
    "ax.set_title('Label')\n",
    "\n",
    "plt.savefig('forward_img.png')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-0663b191d5df>, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0663b191d5df>\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    print(\"------ Finished Training ------\")\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "### 3. Train the model\n",
    "# tempUnet.train()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('\\ndevice :', device)\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "# batch_size = \n",
    "num_epoch = 2\n",
    "\n",
    "# input, label data setting\n",
    "train_tensor = torch.from_numpy(np_train_list[0])\n",
    "train_tensor = train_tensor.reshape(1, 4, 240, 240, 128)\n",
    "\n",
    "label_tensor = torch.from_numpy(np_label_list[0])\n",
    "# label_tensor = label_tensor.reshape(1, 1, 240, 240, 128)\n",
    "\n",
    "t_inputs = [train_tensor]\n",
    "t_targets = [label_tensor]\n",
    "\n",
    "# print('\\ninput shape :', inputs[0].shape)\n",
    "# print('target shape :', targets[0].shape)\n",
    "\n",
    "net = UNet().to(device)\n",
    "# loss_fn = dice_coef()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "t_loss_arr = []\n",
    "v_loss_arr = []\n",
    "\n",
    "print('\\n\\n------ Hyper Params ------')\n",
    "print(\"learning rate: %.4e\" % lr)\n",
    "# print(\"batch size: %d\" % batch_size)\n",
    "print(\"number of epoch: %d\" % num_epoch)\n",
    "\n",
    "print('\\n\\n------ Start Training ------')\n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    # train the model\n",
    "    net.train()\n",
    "    for t_input, t_label in zip(t_inputs, t_targets):\n",
    "        # Forward propagation\n",
    "        t_input = t_input.cuda()\n",
    "        t_label = t_label.cuda()\n",
    "        \n",
    "        t_output = net(t_input.float())\n",
    "        \n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()    # 역전파 실행 전 grad 값 0으로 만듦\n",
    "        loss = 0\n",
    "        '''\n",
    "        max를 1로 나머지 0 으로 만드는 코드 추가...         \n",
    "        '''\n",
    "        for i in range(len(channels)):\n",
    "            loss_ = dice_coef(t_output[0, i, :, :, :], t_label[:, :, :, :])\n",
    "            loss += loss_\n",
    "        loss = (loss / len(channels))\n",
    "        loss.backward()          # 매개변수에 대한 loss의 grad 값 계산\n",
    "        optimizer.step()         # 매개변수 갱신\n",
    "    \n",
    "        t_loss_arr += [loss.item()]\n",
    "        \n",
    "        print(\"Train: EPOCH %04d / %04d | LOSS %.4f\" %(epoch, num_epoch, np.mean(t_loss_arr)))\n",
    "    \n",
    "#     # validate the model\n",
    "#     net.eval()\n",
    "#     for v_input, v_label in zip(v_inputs, v_targets):\n",
    "#         v_input = v_input.cuda()\n",
    "#         v_label = v_label.cuda()\n",
    "        \n",
    "#         v_output = net(v_input.float())\n",
    "        \n",
    "#         loss = 0\n",
    "#         for i in range(len(channels)):\n",
    "#             loss_ = dice_coef(v_output[0, i, :, :, :], v_label[:, :, :, :])\n",
    "#             loss += loss_\n",
    "#         loss = (loss / len(channels))\n",
    "#         v_loss_arr += [loss.item()]\n",
    "#         print(\"Valid: EPOCH %04d / %04d | LOSS %.4f\" %(epoch, num_epoch, np.mean(v_loss_arr)))\n",
    "\n",
    "print(\"------ Finished Training ------\")\n",
    "plt.plot(np.array(t_loss_arr), 'y')\n",
    "# plt.plot(np.array(v_loss_arr), 'c')\n",
    "plt.title('Loss Graph')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend((['train loss', 'validation loss']))\n",
    "plt.savefig('loss graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c75e03e9b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp_test_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtestdirnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestdirnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_sub_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "### 4. Test the model\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)    # numpy 생략(...) 없애기\n",
    "\n",
    "test_dir = base_dir + 'test/'\n",
    "\n",
    "test_sub_dir = []\n",
    "test_img_list = []\n",
    "label_img_list = []\n",
    "np_test_data_list = []\n",
    "\n",
    "testdirnames = os.listdir(test_dir)\n",
    "for dirname in testdirnames:\n",
    "    test_sub_dir.append(dirname)\n",
    "    \n",
    "for test_sub_path in test_sub_dir:\n",
    "    test_img_list.append([os.path.join(test_dir + test_sub_path + '/' + test_sub_path + '_' + channel + '.nii.gz') for channel in channels])\n",
    "    label_img_list.append([os.path.join(test_dir + test_sub_path + '/' + test_sub_path + '_seg.nii.gz')])\n",
    "\n",
    "# predict the output image\n",
    "for test_img in test_img_list[0]:\n",
    "    test_nii = nib.load(test_img)\n",
    "    np_test_data = np.array(test_nii.get_fdata()[:, :, 14:142])\n",
    "    np_test_data = np.reshape(np_test_data, (1, 240, 240, 128))\n",
    "    np_test_data_list.append(np_test_data)\n",
    "np_test_data = np.concatenate(np_test_data_list, axis = 0)\n",
    "test_tensor = torch.from_numpy(np_test_data)\n",
    "test_tensor = test_tensor.reshape(1, 4, 240, 240, 128)\n",
    "test_tensor = test_tensor.cuda()\n",
    "\n",
    "predict_img = net(test_tensor.float())\n",
    "predict_img = predict_img.cpu()\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 1\n",
    "cols = 2\n",
    "custom_depth = 65\n",
    "\n",
    "# load the label image\n",
    "for label_img in label_img_list[0]:\n",
    "    print(label_img)\n",
    "    label_nii = nib.load(label_img)\n",
    "    label_img = np.array(label_nii.get_fdata()[:, :, 14:142])\n",
    "    label_img = label_img[:, :, custom_depth]\n",
    "    ax = fig.add_subplot(rows, cols, 1)\n",
    "    ax.imshow(label_img)\n",
    "    ax.set_title('Label')\n",
    "\n",
    "## predict image\n",
    "np_predict_img = predict_img.detach().numpy()\n",
    "np_predict_img = np.array(np_predict_img)\n",
    "np_predict_img = np_predict_img.argmax(1)\n",
    "test_result = np_predict_img[0, :, :, custom_depth]\n",
    "ax = fig.add_subplot(rows, cols, 2)\n",
    "ax.imshow(test_result)\n",
    "ax.set_title('Predict')\n",
    "\n",
    "plt.savefig('result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BraTS",
   "language": "python",
   "name": "brats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
